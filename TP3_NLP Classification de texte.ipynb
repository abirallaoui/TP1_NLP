{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30211b2f",
   "metadata": {},
   "source": [
    "#### Importation des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a39ec667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc1eef",
   "metadata": {},
   "source": [
    "#### Lecture des donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3507b337",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>cv_tag</th>\n",
       "      <th>html_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>0</td>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>1</td>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>2</td>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>3</td>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>cv000</td>\n",
       "      <td>29590</td>\n",
       "      <td>4</td>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>20</td>\n",
       "      <td>that lack of inspiration can be traced back to...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>21</td>\n",
       "      <td>like too many of the skits on the current inca...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>22</td>\n",
       "      <td>after watching one of the \" roxbury \" skits on...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>23</td>\n",
       "      <td>bump unsuspecting women , and . . . that's all .</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>9</td>\n",
       "      <td>cv999</td>\n",
       "      <td>14636</td>\n",
       "      <td>24</td>\n",
       "      <td>after watching _a_night_at_the_roxbury_ , you'...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fold_id cv_tag  html_id  sent_id  \\\n",
       "0            0  cv000    29590        0   \n",
       "1            0  cv000    29590        1   \n",
       "2            0  cv000    29590        2   \n",
       "3            0  cv000    29590        3   \n",
       "4            0  cv000    29590        4   \n",
       "...        ...    ...      ...      ...   \n",
       "64715        9  cv999    14636       20   \n",
       "64716        9  cv999    14636       21   \n",
       "64717        9  cv999    14636       22   \n",
       "64718        9  cv999    14636       23   \n",
       "64719        9  cv999    14636       24   \n",
       "\n",
       "                                                    text  tag  \n",
       "0      films adapted from comic books have had plenty...  pos  \n",
       "1      for starters , it was created by alan moore ( ...  pos  \n",
       "2      to say moore and campbell thoroughly researche...  pos  \n",
       "3      the book ( or \" graphic novel , \" if you will ...  pos  \n",
       "4      in other words , don't dismiss this film becau...  pos  \n",
       "...                                                  ...  ...  \n",
       "64715  that lack of inspiration can be traced back to...  neg  \n",
       "64716  like too many of the skits on the current inca...  neg  \n",
       "64717  after watching one of the \" roxbury \" skits on...  neg  \n",
       "64718   bump unsuspecting women , and . . . that's all .  neg  \n",
       "64719  after watching _a_night_at_the_roxbury_ , you'...  neg  \n",
       "\n",
       "[64720 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('movie_review.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bbb287",
   "metadata": {},
   "source": [
    "#### Columns pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba85b5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df[\"text\"]\n",
    "tag=df[\"tag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6a76da6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted from comic books have had plenty...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for starters , it was created by alan moore ( ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to say moore and campbell thoroughly researche...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the book ( or \" graphic novel , \" if you will ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in other words , don't dismiss this film becau...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>that lack of inspiration can be traced back to...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>like too many of the skits on the current inca...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>after watching one of the \" roxbury \" skits on...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>bump unsuspecting women , and . . . that's all .</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>after watching _a_night_at_the_roxbury_ , you'...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tag\n",
       "0      films adapted from comic books have had plenty...  pos\n",
       "1      for starters , it was created by alan moore ( ...  pos\n",
       "2      to say moore and campbell thoroughly researche...  pos\n",
       "3      the book ( or \" graphic novel , \" if you will ...  pos\n",
       "4      in other words , don't dismiss this film becau...  pos\n",
       "...                                                  ...  ...\n",
       "64715  that lack of inspiration can be traced back to...  neg\n",
       "64716  like too many of the skits on the current inca...  neg\n",
       "64717  after watching one of the \" roxbury \" skits on...  neg\n",
       "64718   bump unsuspecting women , and . . . that's all .  neg\n",
       "64719  after watching _a_night_at_the_roxbury_ , you'...  neg\n",
       "\n",
       "[64720 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creation dun nouveau dataframe et l'ajout du Text (features) et Tag (label)\n",
    "NewDf = pd.DataFrame()\n",
    "NewDf[\"text\"] =text\n",
    "NewDf[\"tag\"] =tag\n",
    "NewDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573f8eaf",
   "metadata": {},
   "source": [
    "## Pre-processing des données textuelles :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474ac6f",
   "metadata": {},
   "source": [
    "### Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8031716",
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDf[\"text\"]=NewDf[\"text\"].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f68b7",
   "metadata": {},
   "source": [
    "### Removal of Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0b27542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "NewDf[\"text\"] = NewDf[\"text\"].apply(remove_punctuation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba80181",
   "metadata": {},
   "source": [
    "### Removal of Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "932deaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "NewDf[\"text\"] = NewDf[\"text\"].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c83008c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>films adapted comic books plenty success wheth...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>starters created alan moore eddie campbell bro...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>say moore campbell thoroughly researched subje...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>book graphic novel 500 pages long includes nea...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>words dont dismiss film source</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64715</th>\n",
       "      <td>lack inspiration traced back insipid characters</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64716</th>\n",
       "      <td>like many skits current incarnation saturdayni...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64717</th>\n",
       "      <td>watching one roxbury skits snl come away chara...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64718</th>\n",
       "      <td>bump unsuspecting women thats</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64719</th>\n",
       "      <td>watching anightattheroxbury youll left exactly</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64720 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  tag\n",
       "0      films adapted comic books plenty success wheth...  pos\n",
       "1      starters created alan moore eddie campbell bro...  pos\n",
       "2      say moore campbell thoroughly researched subje...  pos\n",
       "3      book graphic novel 500 pages long includes nea...  pos\n",
       "4                         words dont dismiss film source  pos\n",
       "...                                                  ...  ...\n",
       "64715    lack inspiration traced back insipid characters  neg\n",
       "64716  like many skits current incarnation saturdayni...  neg\n",
       "64717  watching one roxbury skits snl come away chara...  neg\n",
       "64718                      bump unsuspecting women thats  neg\n",
       "64719     watching anightattheroxbury youll left exactly  neg\n",
       "\n",
       "[64720 rows x 2 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NewDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6af5e4",
   "metadata": {},
   "source": [
    "## Entraînement du modèle Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87960042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [films, adapted, comic, books, plenty, success...\n",
       "1        [starters, created, alan, moore, eddie, campbe...\n",
       "2        [say, moore, campbell, thoroughly, researched,...\n",
       "3        [book, graphic, novel, 500, pages, long, inclu...\n",
       "4                     [words, dont, dismiss, film, source]\n",
       "                               ...                        \n",
       "64715    [lack, inspiration, traced, back, insipid, cha...\n",
       "64716    [like, many, skits, current, incarnation, satu...\n",
       "64717    [watching, one, roxbury, skits, snl, come, awa...\n",
       "64718                   [bump, unsuspecting, women, thats]\n",
       "64719    [watching, anightattheroxbury, youll, left, ex...\n",
       "Name: text, Length: 64720, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "# notre texte prétraité\n",
    "preprocessed_text =NewDf[\"text\"]\n",
    "# Tokenize le texte prétraité\n",
    "tokens = preprocessed_text.apply(lambda x: x.split())\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2461b6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(tokens, vector_size=50,min_count=1, window=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f168bfc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.52241181e-03 -1.00752590e-02 -6.95133815e-03 -2.68813851e-03\n",
      "  1.62945427e-02 -7.40428455e-03 -1.47035606e-02  5.07309334e-03\n",
      " -2.24050740e-03 -7.25701277e-04  1.12276282e-02  1.09838611e-02\n",
      "  1.45027246e-02 -6.84975507e-03  1.11495443e-02 -1.74803678e-02\n",
      "  3.65319639e-03 -1.09445974e-02 -2.56523900e-02  1.37499534e-03\n",
      "  7.67212827e-03 -2.44254316e-03  2.63777729e-02  6.85338257e-03\n",
      "  6.24917157e-04  2.35131830e-02 -2.06508264e-02  1.46928225e-02\n",
      " -2.27230281e-04  4.72025495e-05  2.09715944e-02  7.42070097e-03\n",
      "  1.27475942e-02 -6.17375073e-04  1.17977976e-03  2.18528938e-02\n",
      "  1.68753248e-02 -5.05381171e-03  2.36663688e-03 -1.14049744e-02\n",
      " -5.22657670e-03  8.18961486e-03  1.43480478e-02  8.09842162e-03\n",
      "  1.99491694e-03  6.54826732e-03 -4.07608738e-03  1.10645173e-02\n",
      "  1.44755738e-02 -1.30239083e-02]\n"
     ]
    }
   ],
   "source": [
    "# Accédez aux vecteurs de mots\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Obtenez la représentation vectorielle d'un mot spécifique\n",
    "vector_for_word = word_vectors['mot']\n",
    "\n",
    "# Affichez la représentation vectorielle du mot\n",
    "print(vector_for_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26a0be91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'novel' et 'book':  0.9664345\n"
     ]
    }
   ],
   "source": [
    "# Calculer la similarité entre deux mots\n",
    "similarity = model.wv.similarity('novel', 'book')\n",
    "print(\"Similarité entre 'novel' et 'book': \", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3055b6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'page' et 'book':  0.94731915\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('page', 'book')\n",
    "print(\"Similarité entre 'page' et 'book': \", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19a1c828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarité entre 'charact' et 'actor':  0.76376307\n"
     ]
    }
   ],
   "source": [
    "similarity = model.wv.similarity('charact', 'actor')\n",
    "print(\"Similarité entre 'charact' et 'actor': \", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "efd7a100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x1caa4259a10>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtenez les représentations vectorielles des mots\n",
    "word_vectors = model.wv\n",
    "word_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0eadd",
   "metadata": {},
   "source": [
    "## Vectorisation des reviews de movies :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1af7f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = model.wv\n",
    "\n",
    "# Liste pour stocker les vecteurs de chaque critique\n",
    "reviews_vectorized = []\n",
    "\n",
    "# Parcourir chaque liste de tokens dans tokens\n",
    "for review_tokens in tokens:\n",
    "    # Initialiser un vecteur pour la critique\n",
    "    review_vector = np.zeros(model.vector_size)\n",
    "    # Compter le nombre de mots présents dans le modèle Word2Vec pour cette critique\n",
    "    words_count = 0\n",
    "    # Parcourir chaque mot dans la critique\n",
    "    for word in review_tokens:\n",
    "        if word in model.wv:\n",
    "            # Si le mot est présent dans le vocabulaire du modèle, ajoutez son embedding à la représentation de la critique\n",
    "            review_vector += model.wv[word]\n",
    "            # Incrémenter le compteur de mots\n",
    "            words_count += 1\n",
    "    # Prendre la moyenne des embeddings pour obtenir la représentation de la critique\n",
    "    if words_count != 0:\n",
    "        review_vector /= words_count\n",
    "    # Ajouter le vecteur de critique à la liste des vecteurs de critiques\n",
    "    reviews_vectorized.append(review_vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3dd44d",
   "metadata": {},
   "source": [
    "## Division des données :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9701c310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement (features) : 51776   Taille de l'ensemble de test (features) : 12944\n",
      "Taille de l'ensemble d'entraînement (cibles) : 51776    Taille de l'ensemble de test (cibles) : 12944\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Définir les features (text) et la cible (tag)\n",
    "y = NewDf[\"tag\"]\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews_vectorized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Afficher les tailles des ensembles\n",
    "print(\"Taille de l'ensemble d'entraînement (features) :\", len(X_train),\"  Taille de l'ensemble de test (features) :\", len(X_test))\n",
    "\n",
    "print(\"Taille de l'ensemble d'entraînement (cibles) :\", len(y_train),\"   Taille de l'ensemble de test (cibles) :\", len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c269a",
   "metadata": {},
   "source": [
    "## Construction d'un classificateur :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "289ae766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Convertir les étiquettes en valeurs numériques:\"pos\" en 1 et \"neg\" en 0\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.fit_transform(y_test)\n",
    "\n",
    "y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d8bd2c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Instanciation du modèle LogisticRegression\n",
    "reg = LogisticRegression(solver='saga')\n",
    "\n",
    "# Entraînement du modèle\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e1bbaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88dae6a",
   "metadata": {},
   "source": [
    "## Évaluation du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea120d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5686804697156984 \n",
      "Precision 0.5622015581804474 \n",
      "Recall: 0.6806633196409554 \n",
      "F1-score: 0.6157869382699058\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calcul de l'accuracy,la precision,recall,F1-score\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, )\n",
    "recall = recall_score(y_test, y_pred, )\n",
    "f1 = f1_score(y_test, y_pred, )\n",
    "\n",
    "print(\"Accuracy:\", accuracy,\"\\nPrecision\", precision,\"\\nRecall:\", recall,\"\\nF1-score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427c4f7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
